['{"name": "Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Unveiling AI\'s Potential Through Tools, Techniques, and Applications", "url": "http://arxiv.org/abs/2410.01268v2", "authors": "Pohsun Feng, Ziqian Bi, Yizhu Wen, Xuanhe Pan, Benji Peng, Ming Liu, Jiawei Xu, Keyu Chen, Junyu Liu, Caitlyn Heqi Yin, Sen Zhang, Jinlang Wang, Qian Niu, Ming Li, Tianyang Wang", "publication_date": "2024-12-12", "out_references": [], "num_out": 0}', '{"name": "Toward Large-scale Spiking Neural Networks: A Comprehensive Survey and Future Directions", "url": "http://arxiv.org/abs/2409.02111v1", "authors": "Yangfan Hu, Qian Zheng, Guoqi Li, Huajin Tang, Gang Pan", "publication_date": "2024-08-19", "out_references": ["Towards High-performance Spiking Transformers from ANN to SNN Conversion", "SpikingMiniLM: energy-efficient spiking transformer for natural language understanding", "One-step Spiking Transformer with a Linear Complexity", "SpikeLLM: Scaling up Spiking Neural Network to Large Language Models via Saliency-based Spiking", "TE-Spikformer:Temporal-enhanced spiking neural network with transformer"], "num_out": 117}', '{"name": "Transformers in Healthcare: A Survey", "url": "http://arxiv.org/abs/2307.00067v1", "authors": "Subhash Nerella, Sabyasachi Bandyopadhyay, Jiaqing Zhang, Miguel Contreras, Scott Siegel, Aysegul Bumin, Brandon Silva, Jessica Sena, Benjamin Shickel, Azra Bihorac, Kia Khezeli, Parisa Rashidi", "publication_date": "2023-06-30", "out_references": ["The shaky foundations of large language models and foundation models for electronic health records", "Bias in artificial intelligence algorithms and recommendations for mitigation", "Vision Transformers in medical computer vision - A contemplative retrospection", "QLoRA: Efficient Finetuning of Quantized LLMs", "PaLM 2 Technical Report"], "num_out": 495}']
